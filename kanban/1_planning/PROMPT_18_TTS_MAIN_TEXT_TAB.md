# Prompt: Rebuild TTS Main Text Tab (Tab 8) with Kokoro TTS Integration

## Objective

Rebuild the TTS Main Text tab (Tab 8) from a static mockup into a functional dashboard that:
1. Loads lesson text from generated lesson files (`/write-lesson` output)
2. Connects to Kokoro-FastAPI on P520 for fast TTS with word-level timestamps
3. Generates 3 voice variants simultaneously for comparison
4. Provides word-level timestamp JSON output for Remotion video sync
5. Applies a pronunciation dictionary for technical terms
6. Provides playback, download, and export to Remotion

This tab generates the **main lesson narration audio** — the full spoken version of a lesson's content. This is different from Tab 7 (TTS Intro Video) which generates only the 60-90 second intro narration using F5-TTS voice cloning. Tab 8 uses Kokoro TTS which is faster, has 67 voices, and produces word-level timestamps needed for precise video sync.

---

## Context: Integration with Other Dashboard Tabs

### Tab-by-Tab Integration

| Tab | Direction | Integration |
|-----|-----------|-------------|
| **Tab 6: Lesson Writer** | ← Input | The lesson markdown file generated by `/write-lesson` is the source text. Tab 8 should load lesson content from `generated_lessons/month*/lesson_*_{slug}.md`. The Lesson Writer may offer a "Send to TTS Main" button. |
| **Tab 7: TTS Intro Video (F5-TTS)** | Sibling | Tab 7 generates the intro narration (voice-cloned, short). Tab 8 generates the full lesson narration (Kokoro, long). Different TTS engines, different output directories, different use cases. They share the `tts_sessions/` parent directory. |
| **Tab 9: Remotion Studio** | → Output | Word timestamps from Kokoro enable precise slide transitions in Remotion. The "Export for Remotion" button should save timestamps JSON alongside the audio. Tab 9 can use these for word-level sync. |
| **Tab 5: Syllabus Manager** | ← Input | Lesson metadata (title, month, number) for file naming and organisation. |

### Shared Data Paths (on P520 in Docker)

| Data | Path | Used By |
|------|------|---------|
| Lesson files | `/data/generated_lessons/month{N}/lesson_{NN}_{slug}.md` | Input to this tab |
| Generated audio | `/home/david/gwth-dashboard/tts_sessions/kokoro_lesson_{NN}/` | Output from this tab (per-lesson directory) |
| Word timestamps | `/home/david/gwth-dashboard/tts_sessions/kokoro_lesson_{NN}/timestamps.json` | Used by Remotion for word-level sync |
| Pronunciation dict | `/home/david/gwth-dashboard/pronunciation_dict.json` | Applied before TTS generation |

---

## Current State

The TTS Main Text tab (lines 5002-5108 in `gwth_dashboard.py`) is a static mockup with:
- Hardcoded stats (67 Available Voices, 2 GB VRAM, 3 Variants per Gen, Yes Word Timestamps)
- A text area with no content
- "Auto-Load from Lesson" and "Apply Pronunciation Dict" buttons — not functional
- 3 voice selectors with 5 hardcoded voice names each
- Generate 3 Variants button — not functional
- Variants Comparison section with waveform placeholders
- Word Timestamps JSON textarea — not functional
- "Export for Remotion" button — not functional

### Kokoro-FastAPI Service on P520

- **API Base URL:** `http://192.168.178.50:8880`
- **Health endpoint:** `http://192.168.178.50:8880/health` (already checked by `check_model_status()`)
- **VRAM:** 2.1 GB when loaded
- **Voices:** 67 available voices
- **Key feature:** Word-level timestamps in output
- **OpenAI-compatible API** (Kokoro-FastAPI follows the OpenAI TTS API format)

### Kokoro-FastAPI API Endpoints

Kokoro-FastAPI follows the OpenAI-compatible TTS API:

```
POST /v1/audio/speech
Body: {
  "model": "kokoro",
  "input": "Text to speak...",
  "voice": "af_heart",
  "response_format": "wav",
  "speed": 1.0
}
Response: Audio bytes (WAV/MP3/etc.)
```

```
GET /v1/audio/voices
Response: { "voices": ["af_heart", "af_sky", "am_michael", ...] }
```

```
POST /v1/audio/speech  (with word timestamps)
Body: {
  "model": "kokoro",
  "input": "Text to speak...",
  "voice": "af_heart",
  "response_format": "wav",
  "return_timestamps": true
}
Response: {
  "audio": "<base64 WAV data>",
  "timestamps": [
    {"word": "Text", "start": 0.0, "end": 0.3},
    {"word": "to", "start": 0.3, "end": 0.45},
    {"word": "speak", "start": 0.45, "end": 0.8}
  ]
}
```

**Important:** Verify the actual Kokoro-FastAPI endpoints by checking `http://192.168.178.50:8880/docs` or `http://192.168.178.50:8880/openapi.json`. The endpoints above follow the Kokoro-FastAPI pattern but may have differences in the timestamp response format.

### Pronunciation Dictionary

Located at `C:/yt-dlp/pronunciation_dict.json` (and deployed to P520). Contains mappings for technical terms that TTS engines mispronounce:

```json
{
  "LLM": "L L M",
  "RAG": "rag",
  "GPT": "G P T",
  "API": "A P I",
  "GWTH": "growth"
}
```

Before sending text to Kokoro, apply these substitutions so the TTS engine pronounces terms correctly.

---

## What the `/write-lesson` Skill Does vs What This Tab Does

### `/write-lesson` Skill (text generation — runs in Claude Code)

| Responsibility | Detail |
|----------------|--------|
| Read enhanced CSV and RAG content | Gathers source material for the lesson |
| Write full lesson markdown | Front matter, objectives, core concepts, examples, summary |
| Structure for readability | Headings, bullet points, code blocks, tables |
| Save lesson file | `generated_lessons/month{N}/lesson_{NN}_{slug}.md` |

### Tab 8: TTS Main Text (audio generation — runs in dashboard)

| Responsibility | Detail |
|----------------|--------|
| Load lesson text | Parse lesson markdown, extract narration-suitable text (strip code blocks, tables, front matter) |
| Apply pronunciation dict | Replace technical terms with phonetic versions before TTS |
| Select voices | Choose 3 different Kokoro voices for comparison |
| Generate 3 variants | Send same text to Kokoro with 3 different voices simultaneously |
| Produce word timestamps | Get word-level timing data from Kokoro for each variant |
| Compare variants | Play back all 3 side-by-side for the user to pick the best one |
| Save selected audio | Save chosen variant WAV + timestamps JSON with pipeline naming |
| Export for Remotion | Make timestamps available for Tab 9 video sync |

---

## What to Build

### Part 1: New API Endpoints

Add these endpoints to `gwth_dashboard.py`:

#### `GET /api/tts/kokoro/status`
Returns Kokoro service status and available voices.

```json
{
  "model_loaded": true,
  "vram_gb": 2.1,
  "available_voices": ["af_heart", "af_sky", "am_michael", ...],
  "voice_count": 67,
  "pronunciation_dict_entries": 42
}
```

#### `GET /api/tts/kokoro/voices`
Proxies to Kokoro's voice list endpoint. Returns all available voices grouped by category (if available).

#### `GET /api/tts/kokoro/lessons`
Lists available lesson files that can be loaded for TTS.

```json
{
  "lessons": [
    {
      "lesson_number": 3,
      "month": 1,
      "title": "Intro to Large Language Models",
      "file_path": "/data/generated_lessons/month1/lesson_03_intro_to_llms.md",
      "word_count": 3200,
      "estimated_duration_min": 21.3,
      "has_audio": false
    }
  ]
}
```

#### `POST /api/tts/kokoro/generate`
Generates audio for a text with a specified voice, returns audio + timestamps.

```json
Request: {
  "text": "The processed lesson text...",
  "voice": "af_heart",
  "speed": 1.0,
  "lesson_number": 3,
  "variant_number": 1,
  "apply_pronunciation_dict": true
}
Response: {
  "status": "success",
  "output_path": "tts_sessions/kokoro_lesson_03/variant_1_af_heart.wav",
  "timestamps_path": "tts_sessions/kokoro_lesson_03/variant_1_af_heart_timestamps.json",
  "duration_seconds": 1280.5,
  "word_count": 3200,
  "file_size_mb": 142.3
}
```

This endpoint should:
1. Apply pronunciation dictionary substitutions if requested
2. Send text to Kokoro-FastAPI with `return_timestamps: true`
3. Save WAV audio to per-lesson directory
4. Save word timestamps JSON alongside
5. Run via `asyncio.to_thread()` — full lesson TTS can take several minutes
6. For long texts, consider chunking (Kokoro may have input length limits) and concatenating output

#### `POST /api/tts/kokoro/generate-variants`
Generates 3 variants in parallel (or sequential) with different voices.

```json
Request: {
  "text": "The processed lesson text...",
  "voices": ["af_heart", "af_sky", "am_michael"],
  "speed": 1.0,
  "lesson_number": 3,
  "apply_pronunciation_dict": true
}
Response: {
  "status": "success",
  "variants": [
    {"voice": "af_heart", "output_path": "...", "timestamps_path": "...", "duration_seconds": 1280.5},
    {"voice": "af_sky", "output_path": "...", "timestamps_path": "...", "duration_seconds": 1295.2},
    {"voice": "am_michael", "output_path": "...", "timestamps_path": "...", "duration_seconds": 1270.8}
  ]
}
```

#### `GET /api/tts/kokoro/pronunciation-dict`
Returns the current pronunciation dictionary.

#### `PUT /api/tts/kokoro/pronunciation-dict`
Updates the pronunciation dictionary (add/edit/remove entries).

#### `GET /api/tts/kokoro/generated`
Lists previously generated audio files.

---

### Part 2: Tab 8 UI Rebuild

Replace lines 5002-5108 in `gwth_dashboard.py` with a functional tab.

#### Header Row
- Title: "TTS Main Text (Kokoro)"
- Kokoro status indicator: green/red dot + "Ready (2.1GB VRAM)" / "Not Loaded" (from `check_model_status()`)

#### Stats Cards (dynamic)
- **Available Voices:** Count from Kokoro API (or cached)
- **VRAM Usage:** Actual from `check_model_status()`
- **Variants per Gen:** 3 (configurable later)
- **Word Timestamps:** "Yes" (always — this is Kokoro's key feature)

#### Left Column: Text Input & Voice Selection

**Lesson selector:** Dropdown populated from `GET /api/tts/kokoro/lessons`. Shows: "Lesson {N}: {title} ({word_count} words, ~{duration} min)"

**"Load Lesson Text" button:** When a lesson is selected:
1. Reads the lesson markdown
2. Extracts narration-suitable text:
   - Strip YAML front matter
   - Strip code blocks (not suitable for narration)
   - Strip tables (convert to prose or skip)
   - Strip markdown formatting (headers become pauses, bullets become sentences)
   - Keep: paragraphs, explanations, examples
3. Populates the text area
4. Updates word count and estimated duration

**Text area:** Large, editable. User can tweak text before generating.
- Word count (live update)
- Estimated duration at ~150 words/min
- Character count

**"Apply Pronunciation Dict" button:** Applies dictionary substitutions to the text in the textarea. Shows a count of substitutions made. Should highlight or list what was changed so user can verify.

**Voice Selection (3 Variants):** Three voice dropdowns, each populated from Kokoro's voice list. Default to three contrasting voices. Each has a "Preview" button that generates a short sample (first ~20 words of the text) so the user can hear the voice before committing to a full generation.

#### Right Column: Generation & Comparison

**"Generate 3 Variants" button:**
1. Validates: text not empty, 3 voices selected, Kokoro loaded
2. Shows generation progress (per-variant if possible)
3. Calls `POST /api/tts/kokoro/generate-variants`
4. On success: populates the variants comparison section

**Status display:** Shows per-variant generation progress. Full lesson text can take several minutes per variant.

**Variants Comparison:**
- 3 columns, one per variant
- Each shows: voice name, duration, waveform visualisation (or simple audio player)
- Play/Pause button per variant
- Download button per variant
- **"Select as Final"** button per variant — marks this variant as the chosen one and saves with the canonical filename

**Word Timestamps (JSON):**
- Read-only textarea showing the timestamps JSON for the selected/latest variant
- Shows format: `[{"word": "Welcome", "start": 0.0, "end": 0.5}, ...]`
- Word count and total duration derived from timestamps

**"Export for Remotion" button:**
- Saves the selected variant's audio and timestamps to the canonical path
- Canonical naming: `tts_sessions/kokoro_lesson_{NN}_final.wav` and `tts_sessions/kokoro_lesson_{NN}_timestamps.json`
- These paths can be referenced by Tab 9 (Remotion Studio) for word-level video sync

#### Generated Audio History (below main content)

**Table of previously generated lesson audio:**
- Lesson number and title
- Voice used
- Duration
- File size
- Date generated
- Play button
- "Load" button (loads into comparison view)

---

## Important Implementation Notes

### JavaScript Escaping
The dashboard uses `HTML_TEMPLATE = """..."""` triple-quoted Python strings. Inside these:
- Use `\\n` not `\n` for JavaScript newlines
- Use `\\x27` not `\'` for single quotes in JS onclick handlers
- This has broken the dashboard multiple times — be careful

### NiceGUI 3.x Patterns
- Use `ui.html(content, sanitize=False)` for raw HTML
- Use `ui.add_body_html('''<script>...</script>''')` for JavaScript
- Tab panels are lazy-rendered — content may not exist in DOM until the tab is clicked
- Use `asyncio.to_thread()` for long-running synchronous calls to prevent UI freezing

### Text Extraction from Lesson Markdown
The lesson markdown contains sections not suitable for narration:
- **Keep:** Introduction paragraphs, concept explanations, practical examples, summary text
- **Strip:** YAML front matter, code blocks (``` ... ```), tables, image references, "Sources Used" tables, exercise instruction details that reference screen actions
- **Convert:** Bullet lists → flowing sentences, headers → natural pauses or topic introductions

This extraction logic should be a reusable Python function since it'll be used by the auto-load feature and potentially by the API.

### Pronunciation Dictionary Application
Apply substitutions **after** text extraction but **before** sending to Kokoro. The dictionary at `pronunciation_dict.json` maps terms to phonetic versions. Apply as case-insensitive whole-word replacements (don't replace "API" inside "capital").

### Long Text Handling
Full lessons can be 3,000+ words (~20+ minutes of audio). Kokoro-FastAPI may have input length limits. The implementation should:
1. Check Kokoro's max input length (from API docs)
2. If text exceeds the limit, split into chunks at sentence boundaries
3. Generate audio for each chunk sequentially
4. Concatenate WAV files (using Python `wave` module or ffmpeg)
5. Adjust timestamps for concatenated chunks (offset by previous chunk durations)

### Audio File Naming Convention
- Variants during comparison: `tts_sessions/kokoro_lesson_{NN}/variant_{V}_{voice_name}.wav`
- Final selected: `tts_sessions/kokoro_lesson_{NN}_final.wav`
- Timestamps: `tts_sessions/kokoro_lesson_{NN}_timestamps.json`

### Error Handling
- If Kokoro is not loaded: show clear message (Kokoro should auto-load, but handle the case)
- If text is too long: show warning with word count and estimated duration
- If generation fails: show error from Kokoro API response
- If variant generation is interrupted: save completed variants, show partial results

---

## Files to Modify

| File | Action | Purpose |
|------|--------|---------|
| `app/gwth_dashboard.py` lines 5002-5108 | REPLACE | Rebuild TTS Main Text tab |
| `app/gwth_dashboard.py` (new endpoint section) | ADD | `/api/tts/kokoro/*` endpoints |

---

## Acceptance Criteria

1. **Kokoro status is live** — The tab shows whether Kokoro is loaded, matching the GPU status bar.

2. **Lesson text auto-loads** — Selecting a lesson from the dropdown loads the extracted narration text with code blocks, tables, and front matter stripped.

3. **Pronunciation dict works** — Clicking "Apply Pronunciation Dict" substitutes technical terms and shows what was changed.

4. **Voice selection works** — All 67 Kokoro voices are available in the dropdowns. Preview plays a short sample.

5. **3 variants generate** — Clicking "Generate 3 Variants" produces 3 audio files with different voices. Progress is shown during generation. UI does not freeze.

6. **Variants comparison works** — All 3 variants can be played back for comparison. User can select the best one.

7. **Word timestamps are produced** — Each variant includes word-level timestamps in JSON format. Timestamps are displayed in the readonly textarea.

8. **Export for Remotion works** — Selected variant's audio and timestamps are saved with canonical filenames that Tab 9 can discover.

9. **Stats are dynamic** — Voice count, VRAM usage reflect actual Kokoro state.

10. **Generation history shows** — Previously generated lesson audio files are listed with metadata.

11. **Long text handling** — Lessons with 3,000+ words are chunked and concatenated correctly with adjusted timestamps.

12. **Cross-tab integration** — Lesson files from `/write-lesson` (via Lesson Writer tab) are automatically discoverable. Audio and timestamps are automatically discoverable by the Remotion Studio tab.

---

## Testing Approach

1. Check Kokoro health: `curl http://192.168.178.50:8880/health`
2. Check Kokoro API docs: `curl http://192.168.178.50:8880/docs`
3. List voices: `curl http://192.168.178.50:8880/v1/audio/voices`
4. Test TTS with a short text: `curl -X POST http://192.168.178.50:8880/v1/audio/speech -d '{"input":"Hello world","voice":"af_heart","model":"kokoro"}' --output test.wav`
5. Test with timestamps enabled
6. Create a test lesson file in `generated_lessons/month1/`
7. Test text extraction from lesson markdown
8. Test pronunciation dict application
9. Test full 3-variant generation with a short text (~100 words)
10. Test the full flow: load lesson → apply dict → select voices → generate → compare → export
