# Prompt: Rebuild Remotion Studio Tab with Slide Sequence Rendering

## Objective

Rebuild the Remotion Studio tab (Tab 9) in the GWTH pipeline dashboard to support **automated intro video rendering** from `slides.json` files generated by the `/write-slides` Claude Code skill. The tab should allow loading a slide sequence JSON, syncing to F5-TTS audio, and rendering a final MP4 — all from the dashboard UI.

---

## Context

### Pipeline Flow
The lesson pipeline generates intro videos through these steps:
1. `/write-intro` skill → narration script markdown
2. `/write-slides` skill → `slides.json` (composition sequence with estimated timings) + storyboard markdown
3. F5-TTS → narration audio WAV file
4. **This tab** → sync timings to actual audio, render final MP4 via Remotion

### Current State
The Remotion Studio tab (lines 5110-5221 in `gwth_dashboard.py`) is a static mockup with:
- Hardcoded stats (8 templates, 3 compositions, 2 rendered videos)
- A template gallery showing 4 templates
- A "Create Composition" form (template, title, audio file, duration)
- A "Rendered Videos" list with 2 hardcoded entries
- None of it is functional — no API calls, no Remotion integration

### Remotion Project Location
`C:/yt-dlp/remotion-project/` on the local machine. On P520 (where the dashboard runs): `/home/david/remotion-project/` (or accessible via the data volume).

### Existing Remotion Compositions
The project has these compositions registered in `src/Root.tsx`, each with Zod-validated props:

**Slide compositions (used in slides.json):**
| Composition | Props Schema |
|---|---|
| `LessonTitle`, `LessonTitle-Clean`, `LessonTitle-GradientAccent`, `LessonTitle-CornerBadge`, `LessonTitle-Minimal`, `LessonTitle-Centered` | `{ month, lesson, part, totalParts, title, durationMins, totalDurationMins }` |
| `BulletPoints`, `BulletPoints-Numbered`, `BulletPoints-Cards`, `BulletPoints-Gradient` | `{ heading, subheading?, bullets[], highlightIndex? }` |
| `CodeBlock`, `CodeBlock-Terminal`, `CodeBlock-SplitView`, `CodeBlock-Minimal` | `{ heading, code, language?, highlightLines?[], typewriter? }` |
| `Timeline`, `Timeline-Modern`, `Timeline-VerticalCards`, `Timeline-Milestones` | `{ title, events[{label, description?, icon?}] }` |
| `ChartAnimation`, `Chart-Horizontal-Classic`, `Chart-Horizontal-Gradient`, `Chart-Horizontal-Pill` | `{ title, data[{label, value, color?}], chartType?, showValues? }` |
| `TextTransition` | `{ texts[], transitionType?, durationPerText?, fontSize? }` |
| `Highlighter` | `{ text, highlights[{phrase, color, delay?}], fontSize? }` |
| `ImageWithText` | `{ heading, bodyText, imageSrc?, imagePosition? }` |
| `GWTHIntro01Minimal`, `GWTHIntro02Bordered`, `GWTHIntro03TopicGrid`, `GWTHIntro04Typewriter`, `GWTHIntro05Wipe`, `GWTHOutro` | Various (title, subtitle, topics, etc.) |
| `TextPreset-01-FadeSlide` through `TextPreset-10-LargeTypewriter` | `{ text, fontSize?, ... }` |
| `LayerDiagram` | `{ layers[], ... }` |
| `ScrollingScreen` | `{ ... }` |

### slides.json Format (output of /write-slides skill)
```json
{
  "lessonNumber": 3,
  "lessonTitle": "Intro to Large Language Models",
  "month": 1,
  "totalDurationSeconds": 80,
  "totalFrames": 2400,
  "fps": 30,
  "audioFile": "tts_sessions/f5_intro_lesson_03.wav",
  "slides": [
    {
      "id": "slide_01_branding",
      "composition": "GWTHIntro01Minimal",
      "startFrame": 0,
      "durationFrames": 120,
      "durationSeconds": 4.0,
      "narrationSync": "Opening — GWTH.ai branding",
      "props": {
        "title": "GWTH.ai",
        "subtitle": "Month 1: AI Fundamentals"
      }
    },
    {
      "id": "slide_02_title",
      "composition": "LessonTitle-GradientAccent",
      "startFrame": 120,
      "durationFrames": 210,
      "durationSeconds": 7.0,
      "narrationSync": "Welcome to lesson three...",
      "props": {
        "month": 1,
        "lesson": 3,
        "part": 1,
        "totalParts": 1,
        "title": "Intro to Large Language Models",
        "durationMins": 60,
        "totalDurationMins": 60
      }
    }
  ]
}
```

### GWTH Theme
The Remotion project uses a theme at `src/styles/gwth-theme.ts` with:
- Dark backgrounds: `#1a1a1a`, `#2a2a2a`, `#3a3a3a`
- Accent colours: cyan `#00BCD4`, green `#04B164`, purple `#764AF5`, pink `#E73C79`, yellow `#EAC603`
- Minimum font size: 40px for all content text
- GWTH watermark on all compositions

### Dashboard Tech Stack
- **Framework:** NiceGUI 3.x (Python)
- **File:** `app/gwth_dashboard.py` — single file, tab 9 starts at line 5110
- **Deployment:** Docker on P520 (`192.168.178.50:8088`), deploy via `docker cp` + restart
- **Pattern:** All tabs follow the same structure — stats cards at top, functional sections below

### F5-TTS Audio Output
- F5-TTS generates WAV files saved to `tts_sessions/` directory
- Kokoro TTS (Tab 8) produces word-level timestamps as JSON
- Audio files are on P520 at `/home/david/gwth-dashboard/tts_sessions/`

---

## What to Build

### Part 1: Remotion `SequencePlayer` Composition

**File:** `C:/yt-dlp/remotion-project/src/compositions/SequencePlayer.tsx`

A new Remotion composition that:
1. Accepts a `slides` array as input props (matching the `slides.json` format)
2. Accepts an `audioSrc` string prop for the narration audio file path
3. Renders each slide as a `<Sequence from={startFrame} durationInFrames={durationFrames}>` element
4. Inside each `<Sequence>`, renders the specified composition with its props — this means dynamically selecting the component based on the `composition` string field
5. Adds an `<Audio src={audioSrc}>` track that plays across the entire composition
6. Total duration = `totalFrames` from the JSON

**Component mapping:** You'll need a lookup map from composition name string → React component:
```typescript
const COMPOSITION_MAP: Record<string, React.ComponentType<any>> = {
  'LessonTitle': LessonTitle,
  'LessonTitle-GradientAccent': LessonTitleGradientAccent,
  'BulletPoints': BulletPoints,
  'BulletPoints-Numbered': BulletPointsNumbered,
  // ... all compositions from Root.tsx
};
```

**Register in Root.tsx:** Add a new `<Composition>` entry for `SequencePlayer` with appropriate default props and Zod schema.

### Part 2: Audio Timing Sync API Endpoint

**File:** `app/gwth_dashboard.py` (new endpoint)

```
POST /api/remotion/sync-timing
Body: { "slides_json_path": "/path/to/slides.json", "audio_file_path": "/path/to/audio.wav" }
Response: { "status": "synced", "original_duration_seconds": 80, "actual_duration_seconds": 74.5, "adjusted_slides_path": "/path/to/slides_synced.json" }
```

Logic:
1. Read the audio file duration using Python `wave` module (or `ffprobe` as fallback)
2. Read the slides JSON
3. Calculate the ratio: `actual_audio_duration / estimated_total_duration`
4. Proportionally scale every slide's `startFrame` and `durationFrames` by that ratio
5. Update `totalDurationSeconds` and `totalFrames`
6. Write the synced JSON to a new file (`_synced.json` suffix)
7. Return the result

### Part 3: Remotion Studio Tab Rebuild

**File:** `app/gwth_dashboard.py` (replace lines 5110-5221)

Rebuild Tab 9 with these sections (top to bottom):

#### Header Row
- Title: "Remotion Studio"
- Status indicator: green/yellow/red dot + text showing if Remotion project is accessible
- "Open Remotion Studio" button (opens `http://localhost:3000` in new tab)

#### Stats Cards (dynamic)
- Templates count (read from `compositions.config.json`)
- Slides JSON files found (scan `generated_lessons/` for `*_slides.json`)
- Rendered videos count (scan for `*.mp4` in output directory)
- Output quality: "1080p"

#### Load & Preview Section
- **File selector:** Dropdown listing all `*_slides.json` files found in `generated_lessons/`
- **"Load" button:** Reads the selected JSON and populates the preview
- **Slide preview table:** Shows each slide as a row:
  - Slide number
  - Composition name (with colour badge matching template type)
  - Duration (seconds)
  - narrationSync text (first 50 chars)
  - Props summary (truncated)
- **Storyboard preview:** Reads the corresponding `_storyboard.md` and displays it

#### Audio Sync Section
- **Audio file selector:** Dropdown listing WAV files in `tts_sessions/`
- **"Sync Timing" button:** Calls `POST /api/remotion/sync-timing` with selected slides JSON + audio file
- **Status display:** Shows original vs actual duration, scaling ratio applied
- **Synced JSON path:** Shows the output file path

#### Render Section
- **"Render to MP4" button:** Triggers Remotion CLI render:
  ```bash
  npx remotion render src/index.ts SequencePlayer out/lesson_NN_intro.mp4 --props='<synced slides JSON>'
  ```
- **Progress indicator:** Poll render progress (Remotion CLI outputs progress to stdout)
- **Output display:** Show rendered video filename, size, duration when complete

#### Rendered Videos List (dynamic)
- Scan output directory for MP4 files
- Each row: filename, file size, duration, date rendered
- Play button (opens in browser)
- Download button

---

## Important Implementation Notes

### JavaScript Escaping
The dashboard uses `HTML_TEMPLATE = """..."""` triple-quoted Python strings. Inside these:
- Use `\\n` not `\n` for JavaScript newlines
- Use `\\x27` not `\'` for single quotes in JS onclick handlers inside Python triple-quoted strings
- This has broken the dashboard multiple times — be careful

### NiceGUI 3.x Patterns
- Use `ui.html(content, sanitize=False)` for raw HTML
- Use `ui.add_body_html('''<script>...</script>''')` for JavaScript — `ui.html()` cannot contain `<script>` tags
- Tab panels are lazy-rendered — content may not exist in DOM until the tab is clicked. Use MutationObserver or retry patterns.
- Use `asyncio.to_thread()` for any long-running synchronous calls to prevent UI freezing

### File Paths
- Dashboard runs on P520 in Docker. Data paths start with `/data/` (mapped from `/home/david/gwth-pipeline`)
- Generated lessons: `/data/generated_lessons/`
- TTS sessions: `/home/david/gwth-dashboard/tts_sessions/`
- Remotion project: May need to be accessible from the container or called via SSH

### Remotion CLI Access
The dashboard Docker container may not have Node.js/Remotion installed. Options:
1. **SSH to P520 host** and run `npx remotion render` there (simplest)
2. **Add Node.js to the Docker image** (increases image size)
3. **Separate Remotion render service** (overkill for now)

Recommend option 1: SSH from container to host for rendering. The dashboard already has SSH access patterns.

### Error Handling
- If slides.json has an invalid composition name, report which slide and what name was invalid
- If audio file doesn't exist, show a clear error and suggest generating TTS first
- If Remotion render fails, capture stderr and display it

---

## Files to Create / Modify

| File | Action | Purpose |
|------|--------|---------|
| `C:/yt-dlp/remotion-project/src/compositions/SequencePlayer.tsx` | CREATE | New composition that renders slide sequences |
| `C:/yt-dlp/remotion-project/src/Root.tsx` | MODIFY | Register SequencePlayer composition |
| `C:/yt-dlp/remotion-project/src/compositions/index.ts` | MODIFY | Export SequencePlayer |
| `app/gwth_dashboard.py` lines 5110-5221 | REPLACE | Rebuild Remotion Studio tab |
| `app/gwth_dashboard.py` (new endpoint section) | ADD | `/api/remotion/sync-timing` endpoint |

---

## Acceptance Criteria

1. **SequencePlayer renders slides.json** — Given a valid slides.json with 5+ slides using different compositions, Remotion renders a single MP4 with all slides in sequence and audio playing throughout.

2. **Audio sync works** — Given a slides.json with 80s estimated duration and a WAV file that's actually 74.5s, the sync endpoint produces a new JSON where all frame timings are proportionally scaled and `totalFrames` matches the audio duration.

3. **Tab loads slides JSON** — Selecting a slides.json from the dropdown shows all slides in a preview table with composition names, durations, and narration sync text.

4. **Render from UI** — Clicking "Render to MP4" with a loaded (and optionally synced) slides.json triggers a Remotion render and shows the output MP4 in the rendered videos list.

5. **Stats are dynamic** — Template count, slides JSON count, and rendered video count update from actual file system state.

---

## Testing Approach

1. Create a test `slides.json` manually with 3-4 slides using simple compositions (LessonTitle, BulletPoints, TextTransition)
2. Generate a test WAV file using F5-TTS from Tab 7
3. Test the sync-timing endpoint
4. Test SequencePlayer rendering via CLI: `npx remotion render src/index.ts SequencePlayer out/test.mp4 --props='...'`
5. Test the full tab UI flow in the dashboard
